\documentclass{standalone}
    % preamble: usepackage, etc.
\begin{document}
\begin{chineseabstract}
随着我国信息化建设的不断推进，以及移动互联网的不断发展，
互联网中的信息开始爆炸式的增长，进入了以短文本信息为主的碎片化信息时代。
如何从浩如烟海的信息碎片中准确的获取有用信息，成了学者及商业公司关注的焦点。
本文主要研究了中文短文本分类的相关技术，改进了传统词向量与字向量的训练模型，
然后以此对经典文本分类模型进行有效改进，
设计并实现了一个适合中文短文本的分类模型。本文的主要工作包括了以下几个方面：
\begin{enumerate}
    \item 通过研究传统词向量模型在中文语料上的不足，本文改进了原有的训练模型，引入
    了中文汉字信息以及偏旁部首信息，让词向量模型能够获得额外的共现信息，
    更加适合中文文本。并通过部首转换机制，
    将部首替换为与其对应的汉字，使词向量模型能够更好地识别具有语义联系的词语
    ，让具有相似语义的单词能够在向量空间中彼此靠近，性能更优，解释性更强。并且以此为基础提出了
    另一个字向量模型，弥补了分词错误对词向量的影响，为后续的分类模型提供了更加丰富的语义信息。
    \item 本文将卷积神经网络与循环神经网组合使用，引入Attention Model技术，
    设计了一个全新的特征提取网络。
    该网络采用了k-max池化与双向循环神经网络技术，具有更好的特征提取能力，能够有效的识别并提取
    文本数据中的语义特征。通过Attention Model技术，
    网络更加专注分类特征的提取，剔除了无效特征，整体上提升了特征向量质量，
    从而提升分类模型的分类效果。
    \item 本文采用双通道的短文本分类模型结构，结合了字向量与词向量的文本数据，
    从两个不同的文本表示中对同一段文本提取文本特征，
    极大的丰富了输入短文本的文本信息，有效提升了分类效果，
    并通过与其他同类模型的对比实验，证明了模型的可行性。
\end{enumerate}


\chinesekeyword{短文本，文本分类，深度学习，Attention技术，中文词向量}
\end{chineseabstract}


\begin{englishabstract}
    With the continuous information construction in China and the development of Mobile Internet, 
    information from the Internet grows explosively, 
    the age of fragmented information which is based on short text information is coming. 
    Therefore, the way to accurately extract required information becomes the focus of scholars and commercial company.
    This study presents the research in Chinese short text classification technologies, 
    the training model of word embedding and character embedding is improved. 
    In addition, the classic text classification model is enhanced effectively. 
    Then, a classification model which is suitable for Chinese short text is designed and implemented. 
    This paper introduces works in three parts:
    
    First,Based on the research of the deficiency of word embedding in Chinese corpus, 
    previous training model is improved by adding Chinese characters and radicals information, 
    which provides extra cooccurrence information to word embedding. 
    It is more suitable for Chinese text. 
    Moreover, radical transformation mechanism which changes radical 
    to the corresponding Chinese character makes word embedding effectively to identify words with connected semantic. 
    Thus, words with similar semantic is closer in vector space so that the performance and explanatory is better. 
    Based on this, character embedding, which reduces the effect to word embedding from word break error, 
    provides richer semantic information for subsequent classification models. 

    Second, the convolutional neural network and recurrent neural network 
    are combined to design a new feature extraction network 
    using Attention Model technology. 
    The network employs k-max pooling and bidirectional cyclic neural network technology which 
    has stronger feature extraction capability to identify and extract semantic feature from text data. 
    Using Attention Model technology, Internet pays more attention to extract classification features 
    and removes invalid features. 
    Therefore, quality of feature vector is improved while classification effect of models is more obvious.

    Third,this paper adopts a dual-channel short text classification model, 
    which combines text data of word embedding and character embedding, 
    to extract text feature from two different texts. 
    It greatly enriches text information of short text and enhanced the effect of classification. 
    Besides, comparing with other similar models in experiments, 
    the model is proved feasibly.

\englishkeyword{Short Text, Text Classification, Deep Learning, Attention Technology, 
Chinese Word Embedding}
\end{englishabstract}

\end{document}
    