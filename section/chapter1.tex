\thesischapterexordium
\section{研究工作的背景与意义}
随着信息化进程的不断推进，我国互联网市场空前繁荣。从WEB2.0时代开始，
到如今的“互联网+”时代，互联网已经融入了人们的生活中，也对各行各业产生了深远的影响。
根据中国互联网络信息中心发布的《第40次中国互联网络发展状况统计报告\footnote{\url{http://www.cnnic.net.cn/hlwfzyj/hlwxzbg/hlwtjbg/201708/P020170807351923262153.pdf}}》显示，
截止到2017年6月，我国网民规模达到7.51亿，其中手机网民更是达到7.24亿，
占总体网民的96.3\%，使用率排名前三的互联网应用分别是即时通信（92.1\%）、网络新闻（83.1\%）、
搜索引擎（81.1\%），使用率最高的三个app应用则是微信（84.3\%）、QQ（65.8\%）、微博（38.7\%）。
可以明显看出，人们使用互联网以及获取信息的方式，已经从以前的桌面台式电脑，
转变为移动端的手机、IPAD等掌上设备。

移动设备的盛行，使得人们发布和接收信息都更加方便，
据统计，在2012年，微博用户已经增长到3.68亿，其中69\%通过移动设备登陆，
每天能产生1.17亿条微博。手机用户的大量增加，让互联网信息爆炸式增长，
并且产生了大量碎片化的信息，如微博、QQ说说、留言、商品评论等。据有关部门统计，互联网全体文本信息中，
80\%以上属于内容较少的短文本信息。

如果能够有效分析这些短文本，对其进行精确的分类，可以方便用户有效的梳理这些浩如烟海的文本并掌握对自身有用的信息，
商家也能够根据信息的分类提供更加优质的服务。
例如，内容提供商，如新浪微博、知乎等，可以对其提供的信息进行分类，让用户快速获取自己感兴趣的某一类信息，
同时商家也可以统计用户浏览过的信息类，精确投放用户感兴趣的广告，减少无关广告对用户体验的伤害；
政府相关部门可以根据一段时间内大众发布的微博或朋友圈等信息，掌握当前的热门话题、集中关注点，
监控当前的社会舆情；电子商务平台，如淘宝、京东等，可以利用情感分类技术，提取商品的正面评论与负面评论给用户，
让用户能够更好的筛选与判断优质商品。

但是和传统文章相比，短文本过于短小（通常在100字以内，一般是一句话的长度），
不能提供足够的词共现（word co-occurrence）或上下文，以至于很难从中提取出有效的文本特征\citing{song2014short}。
因此，常规机器学习技术与文本分类算法很难直接应用在短文本之上。那么如何准确高效的对短文本进行分类，
成为了互联网从业者与互联网技术学者所面临的一个重要难题，其突破也会具有重要的商业价值与使用价值。

\section{国内外研究现状}
随着互联网中短文本信息的增多，短文本分类领域得到了广泛的关注，越来越多的学者投入到短文本分类的研究之中。
但由于短文本短小、信息分散的特性，传统基于词频、词共现的分类方法通常得不到较好的效果，比如贝叶斯方法（Naive Bayes）、
最大熵模型（Maximum Entropy Model）、K-邻近算法（K Nearest Neighbors）以及支持向量机（Support Vector Machines，SVMs）。
因此学者们开始尝试从其他方面来改进短文本分类算法，比如语义分析（sematic analysis）、半监督（semi-supervised）算法和集中模型（ensemble models）。

在语义分析方面，纽约大学的Sarah Zelikovitz等人\citing{zelikovitz2005transductive}通过隐含语义索引算法（Latent Semantic Index，LSI）对短文本的语义分析，将文本中的词映射到潜在语义空间，来捕获文本单词之间的相关性，提升分类效果；
清华大学的Chen等人\citing{chen2011short}通过改进的隐含狄利克雷分布（Latent Dirichlet allocation，LDA）模型，将短文本中的单词与多个粒度的话题相关联，从而拓展短文本特征。

在半监督学习方面，Juan Manuel Cabrera等人\citing{cabrera2013distributional}根据分布式词语表示算法（Distributional Term Representations，DTRs），用半监督的方式统计语料中的文档出现特征以及词语共现信息，形成每个词语的上下文信息，最后强化文本表示，以此来克服短文本处理中长度过短、信息高度分散的难点。

中国科学院自动化研究所的冯晓等人\citing{feng2013chinese}则构造了一种集中学习模型，直接确立短文本实例与某一主题直接的相关性，而不是将短文本表示为权重向量，取得了超过向量空间模型（Vector Space Model，VSM）的效果。

随着神经网络与深度学习逐渐兴起，并在计算机视觉、语音识别等领域取得了不错的成果，
越来越多的学者注意到深度学习模型对于特征提取与数据建模上的优势，开始尝试在在自然语言处理问题中引入。而通过神经网络提取出的文本特征向量，可以直接用于其他任务，例如输入传统分类器进行分类。
斯坦福大学的Richard Socher等人\citing{socher2012semantic}构造了一个使用矩阵向量的循环神经网络（MV-RNN），从长度不一致的句子中学习语义信息，
形式长度统一的特征向量，最后放入分类器分类，取得了超过传统文本分类方法的结果；
牛津大学的Nal Kalchbrenner等人\citing{blunsom2014convolutional}提出了动态卷积神经网络（DCNN），利用动态K-max池化的方法，直接获取文本中单词直接的距离关系，避免了对语法分析树的依赖；
哈佛大学的Yoon Kim等人\citing{chen2015convolutional}将动态词向量与预训练好的静态词向量相结合作为同一段文本的两个表示，输入卷积神经网络的两个通道中进行分类，也取得的较好的效果。

但是，随着深度学习使用的逐渐扩大，学者们发现，对于语法复杂、需要分词的中文文本，深度学习模型并不能直接应用，也无法取得英文语料一样的优秀效果。因此，国内学者开始探寻适合中文文本的深度学习模型，也获得了很多不错的成果。

中国科学院自动化研究所的来斯惟等人\citing{lai2015recurrent}设计了一个循环卷积神经网络，在中文长文本分类任务中取得了较好的效果。
纽约大学的张翔等人\citing{zhang2015character}实现了一个字符级别的卷积网络（ConvNets），将中文语句转化为汉语拼音，对中文语料进行分类。
北京大学的李嫣然等人\citing{li2015component}通过在文本表示中引入部首信息，
利用汉字中部首也包含一定语义信息的特点，在连续词袋模型（Continuous Bag-of-Words，CBOW）的基础上，
构造出了一个新的字向量模型，在中文新闻标题分类上获得了明显的效果。

近几年，自然语言处理领域不断发展，一些新的方法也相继出现，2017年，
Google公司开创性的提出注意力（Attention）观点，
认为模型的结果并不是和每一个模型提取出的特征都有密切的关系，
往往一个结果只是由某一个或某几个关键特征所决定的。
这给了学者们新的启示，一些学者于是将注意力观点应用在文本分类之中。
在文献\cite{er2016attention}中，南洋理工大学的Meng Joo Er等人开发的基于注意力池化的卷积神经网络，
利用平行的双向长短期记忆网络构造了一个输入文本的中间向量表示，以此作为卷积神经网络生成的文件特征向量的注意力权重，
最后将经过处理后的文本特征向量输入分类器进行分类；
卡耐基梅隆大学的Zichao Yang等人\citing{yang2016hierarchical}则实现了一个分层注意力网络，整个网络由两层循环神经网络组成，
第一层网络对句子进行建模，经过注意力机制处理之后得到句子的向量表示，
然后第二层根据所有的句子向量得到文章的向量表示，最后根据这个文章向量获得分类结果。

尽管基于注意力机制的文本分类在近几年获得了研究人员的关注并得到了很多成果，但是这些成果大多是基于英文语料的，
如何将该方法推广到其他语言中，并且如何通过注意力机制提升中文文本分类，特别是中文短文本的分类依然是研究人员需要继续的课题。
\section{课题主要内容}
\section{本论文的结构安排}
